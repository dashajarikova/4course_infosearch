{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uotwTtlDasKU"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "OSVx6GVc545_",
    "outputId": "6e81ff27-70cb-42c3-f834-a4353b0b713e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
      "\r",
      "\u001b[K     |███████                         | 10kB 12.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 20kB 2.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 30kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 40kB 2.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 51kB 1.8MB/s \n",
      "\u001b[?25hCollecting dawg-python>=0.7\n",
      "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
      "Collecting pymorphy2-dicts<3.0,>=2.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
      "\u001b[K     |████████████████████████████████| 7.1MB 9.9MB/s \n",
      "\u001b[?25hInstalling collected packages: dawg-python, pymorphy2-dicts, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rYXrJN0P5yV-"
   },
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from math import log\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename='preprocessing.log', \n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%a, %d %b %Y %H:%M:%S',level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5WZZ7yXe6Pgg"
   },
   "outputs": [],
   "source": [
    "def open_data():\n",
    "    data = pd.read_csv(\"quora_question_pairs_rus.csv\", index_col='Unnamed: 0')\n",
    "    \n",
    "    data = data.drop(['question2', 'is_duplicate'], axis=1)[:100]\n",
    "    \n",
    "    data['question1'] = data['question1'].apply(lambda x: preproc(x)) \n",
    "    data.to_csv('preprocessed_data.csv', index=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLNp0_pY6Z8R"
   },
   "outputs": [],
   "source": [
    "def tf_idf_indexing(d): \n",
    "    vec = TfidfVectorizer()\n",
    "    X = vec.fit(d) \n",
    "    df_tfidf = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "    #print(X)\n",
    "    df_tfidf.to_csv('tf_idf_index.csv', index=False)\n",
    "    \n",
    "    joblib.dump(vec, 'tf_idf_vectorizer.pkl') #создаем файл пикл, где все переменные\n",
    "    return df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4JKbeBq6dwb"
   },
   "outputs": [],
   "source": [
    "def bm25_indexing(d, k=2, b=0.75): \n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(d)\n",
    "    term_freq_counts = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    term_freq_counts['sum'] = term_freq_counts.sum(axis=1)\n",
    "    tf_table = term_freq_counts.div(term_freq_counts['sum'], axis=0)\n",
    "    tf_table = tf_table.fillna(0)    \n",
    "    tf_table = tf_table.drop(['sum'], axis=1)\n",
    "    \n",
    "    bin_vectorizer = CountVectorizer(binary=True)\n",
    "    bin_X = bin_vectorizer.fit_transform(d)\n",
    "    bin_counts = pd.DataFrame(bin_X.toarray(), columns=bin_vectorizer.get_feature_names()) \n",
    "    word_counter_dict = {}\n",
    "    for column in bin_counts.columns:\n",
    "        col = bin_counts[column]\n",
    "        sum_ = col.sum()\n",
    "        word_counter_dict[column] = sum_\n",
    "    inverse_counter = pd.DataFrame.from_dict(word_counter_dict, orient='index')\n",
    "    inverse_counter = inverse_counter.transpose()\n",
    "    \n",
    "    #N = d.shape[0]\n",
    "    N = len(d)\n",
    "    idfs = {}\n",
    "    for w in inverse_counter:\n",
    "        idf = log((N - inverse_counter[w] + 0.5)/(inverse_counter[w] +0.5))\n",
    "        idfs[w] = idf\n",
    "    idf_table = pd.DataFrame.from_dict(idfs, orient='index')\n",
    "    idf_table = idf_table.transpose()\n",
    "\n",
    "    sums = term_freq_counts['sum']\n",
    "    avg = term_freq_counts['sum'].mean()\n",
    "    sums_normalized = sums.div(avg)\n",
    "\n",
    "    conversion_table_numerator = tf_table.mul(k+1)\n",
    "    coefficient = sums_normalized.mul(b)\n",
    "    coefficient = coefficient.add(1-b)\n",
    "    coefficient = coefficient.mul(k)\n",
    "    \n",
    "    conversion_table_denominator = tf_table.mul(coefficient, axis=0)\n",
    "    tf_factor = conversion_table_numerator.divide(conversion_table_denominator) \n",
    "    tf_factor = tf_factor.fillna(0)\n",
    "    n = tf_factor.shape[0]\n",
    "    \n",
    "    idf_table = pd.concat([idf_table]*n, ignore_index=True)\n",
    "    bm25_table = tf_factor.mul(idf_table, axis=1)\n",
    "    bm25_table = bm25_table.fillna(0)\n",
    "    bm25_table.to_csv('bm25_index.csv', index=False)\n",
    "    return bm25_table\n",
    "\n",
    "def getting_fasttext(filepath):\n",
    "    fasttext_model = KeyedVectors.load(filepath)\n",
    "    return fasttext_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iFYpMR9I6hj4"
   },
   "outputs": [],
   "source": [
    "def sent_vectorizer(sent, model):\n",
    "    if type(sent) != str:\n",
    "        sent_vector = np.zeros((model.vector_size,))\n",
    "        return sent_vector\n",
    "    sent = sent.split()\n",
    "    lemmas_vectors = np.zeros((len(sent), model.vector_size))\n",
    "    for idx, lemma in enumerate(sent):\n",
    "        if lemma in model.vocab:\n",
    "            lemmas_vectors[idx] = model[lemma]\n",
    "    sent_vector = lemmas_vectors.mean(axis=0)\n",
    "    return sent_vector\n",
    "\n",
    "def fasttext_indexing(d):\n",
    "    model = getting_fasttext('fasttext/model.model')\n",
    "    vectors_dict = {}\n",
    "    for idx, row in d.iterrows():\n",
    "        sent_vec = sent_vectorizer(row.question1, model)\n",
    "        vectors_dict[idx] = sent_vec\n",
    "    data = pd.DataFrame.from_dict(vectors_dict, orient='index')\n",
    "    data.to_csv('fasttext_index.csv', index=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtAkAKza6m_l"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        raw_df = dataframe_opening()\n",
    "        logging.info('made preprocessed dataframe')\n",
    "        del(raw_df)\n",
    "        preproc_df = preproc_opening()\n",
    "        tf_idf_index = tf_idf_indexing(list(preproc_df.question1))\n",
    "        logging.info('made tf-idf dataframe')\n",
    "        del(tf_idf_index)\n",
    "        bm25_index = bm25_indexing(list(preproc_df.question1))\n",
    "        logging.info('made bm25 dataframe')\n",
    "        del(bm25_index)\n",
    "        fasttext_index = fasttext_indexing(preproc_df)\n",
    "        logging.info('made fasttext dataframe')\n",
    "        del(fasttext_index)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.exception(repr(e) + ' while some function')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "XA47u0RDP6Al",
    "outputId": "91898d43-15e0-478f-f574-4f420bc0327a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-10-24 10:14:09--  https://www.dropbox.com/s/jaa5y82qzul6byn/quora_question_pairs_rus.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601b:1::a27d:801\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/jaa5y82qzul6byn/quora_question_pairs_rus.csv [following]\n",
      "--2019-10-24 10:14:09--  https://www.dropbox.com/s/raw/jaa5y82qzul6byn/quora_question_pairs_rus.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc8c8e03a20d8b36bf11099933e8.dl.dropboxusercontent.com/cd/0/inline/ArBkaIY-HUNKyYpy_ESEMdpM3QwkzDqqAZ4JEm1fjIi5wMEqSW92109AlmYtO3khdeSDq0ZBFffejFVdDNpRrFI4zQ5orarQNkQAgG0SN0-lq3K_jjBn10jFYpvWy5mUTYY/file# [following]\n",
      "--2019-10-24 10:14:10--  https://uc8c8e03a20d8b36bf11099933e8.dl.dropboxusercontent.com/cd/0/inline/ArBkaIY-HUNKyYpy_ESEMdpM3QwkzDqqAZ4JEm1fjIi5wMEqSW92109AlmYtO3khdeSDq0ZBFffejFVdDNpRrFI4zQ5orarQNkQAgG0SN0-lq3K_jjBn10jFYpvWy5mUTYY/file\n",
      "Resolving uc8c8e03a20d8b36bf11099933e8.dl.dropboxusercontent.com (uc8c8e03a20d8b36bf11099933e8.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601b:6::a27d:806\n",
      "Connecting to uc8c8e03a20d8b36bf11099933e8.dl.dropboxusercontent.com (uc8c8e03a20d8b36bf11099933e8.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 94499321 (90M) [text/plain]\n",
      "Saving to: ‘quora_question_pairs_rus.csv’\n",
      "\n",
      "quora_question_pair 100%[===================>]  90.12M  62.6MB/s    in 1.4s    \n",
      "\n",
      "2019-10-24 10:14:12 (62.6 MB/s) - ‘quora_question_pairs_rus.csv’ saved [94499321/94499321]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://www.dropbox.com/s/jaa5y82qzul6byn/quora_question_pairs_rus.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "AJY07SLbQuug",
    "outputId": "c7a5bbea-ac3f-4f8e-e7a2-cd9f5e997802"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "Huy--eTsRuvP",
    "outputId": "ac4e26c2-2382-4f95-d19f-7435633dd318"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-10-24 10:19:13--  http://vectors.nlpl.eu/repository/11/181.zip\n",
      "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
      "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2622716217 (2.4G) [application/zip]\n",
      "Saving to: ‘181.zip’\n",
      "\n",
      "181.zip             100%[===================>]   2.44G  21.4MB/s    in 2m 28s  \n",
      "\n",
      "2019-10-24 10:21:42 (16.9 MB/s) - ‘181.zip’ saved [2622716217/2622716217]\n",
      "\n",
      "Archive:  181.zip\n",
      "  inflating: fasttext/meta.json      \n",
      "  inflating: fasttext/model.model    \n",
      "  inflating: fasttext/model.model.vectors_ngrams.npy  \n",
      "  inflating: fasttext/model.model.vectors.npy  \n",
      "  inflating: fasttext/model.model.vectors_vocab.npy  \n",
      "  inflating: fasttext/README         \n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors \n",
    "\n",
    "!wget 'http://vectors.nlpl.eu/repository/11/181.zip' \n",
    "\n",
    "!unzip '181.zip' -d 'fasttext'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "zk0Vg5CvRw3z",
    "outputId": "9f1333ff-e756-4af6-e508-d5d18a10b3d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors \n",
    "\n",
    "fast_model = 'fasttext/model.model'\n",
    " \n",
    "fasttext_model = KeyedVectors.load(fast_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "HOgr799z76jF",
    "outputId": "7762af5c-0595-4286-8801-1df1df4fa098"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "raw_df = open_data()\n",
    "logging.info('made preprocessed dataframe')\n",
    "del(raw_df)\n",
    "preproc_df = preproc_opening()\n",
    "tf_idf_index = tf_idf_indexing(list(preproc_df.question1))\n",
    "logging.info('made tf-idf dataframe')\n",
    "del(tf_idf_index)\n",
    "bm25_index = bm25_indexing(list(preproc_df.question1))\n",
    "logging.info('made bm25 dataframe')\n",
    "del(bm25_index)\n",
    "fasttext_index = fasttext_indexing(preproc_df)\n",
    "logging.info('made fasttext dataframe')\n",
    "del(fasttext_index)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
